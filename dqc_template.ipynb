{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e013d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  name  department_id  first_salary   hire_date\n",
      "0   1  John              1         60000  2016-03-15\n",
      "\n",
      "ðŸ“‹ Found 5 columns in the employees table\n",
      "\n",
      "ðŸš€ Running DQC on 5 columns...\n",
      "\n",
      "ðŸ“Š === Data Quality Summary ===\n",
      "     column_name        column_type  total_rows  null_count  distinct_count  \\\n",
      "0             id            integer          50           0              50   \n",
      "1           name  character varying          50           0              46   \n",
      "2  department_id            integer          50           0              10   \n",
      "3   first_salary            integer          50           0              21   \n",
      "4      hire_date  character varying          50           0              50   \n",
      "\n",
      "  example_value  min_val  max_val  empty_varchar_count  \n",
      "0             1      1.0     50.0                  NaN  \n",
      "1          John      NaN      NaN                  0.0  \n",
      "2             1      1.0     10.0                  NaN  \n",
      "3         60000  55000.0  79000.0                  NaN  \n",
      "4    2016-03-15      NaN      NaN                  0.0  \n",
      "\n",
      "ðŸ“ˆ === Additional Insights ===\n",
      "Total rows in table: 50\n",
      "\n",
      "Columns with highest null percentages:\n",
      "  â€¢ id: 0.0%\n",
      "  â€¢ name: 0.0%\n",
      "  â€¢ department_id: 0.0%\n",
      "  â€¢ first_salary: 0.0%\n",
      "  â€¢ hire_date: 0.0%\n",
      "\n",
      "Columns with low uniqueness (potential duplicates):\n",
      "  â€¢ department_id: 0.2 ratio\n",
      "  â€¢ first_salary: 0.42 ratio\n",
      "  â€¢ name: 0.92 ratio\n",
      "\n",
      "âœ… Data Quality Check completed!\n"
     ]
    }
   ],
   "source": [
    "from postgresql1 import host, database, port, username, password\n",
    "import sqlalchemy\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Create SQLAlchemy connection string for PostgreSQL\n",
    "postgres_url = f\"postgresql://{username}:{password}@{host}:{port}/{database}\"\n",
    "engine1 = sqlalchemy.create_engine(postgres_url)\n",
    "\n",
    "# Query data from PostgreSQL using pandas\n",
    "employees_df = pd.read_sql(\"SELECT * FROM employees\", engine1)\n",
    "print(employees_df.head(1))\n",
    "\n",
    "# Step 3: Get schema information from PostgreSQL\n",
    "schema_query = \"\"\"\n",
    "SELECT \n",
    "    column_name,\n",
    "    data_type as column_type\n",
    "FROM information_schema.columns \n",
    "WHERE table_name = 'employees' \n",
    "    AND table_schema = 'public'\n",
    "ORDER BY ordinal_position\n",
    "\"\"\"\n",
    "schema_df = pd.read_sql(schema_query, engine1)\n",
    "print(f\"\\nðŸ“‹ Found {len(schema_df)} columns in the employees table\")\n",
    "\n",
    "# Step 4: Generate column-specific DQC SQL queries for PostgreSQL\n",
    "def generate_dqc_sql(col_name, col_type, table_name='employees'):\n",
    "    col_quoted = f'\"{col_name.replace(\"\\\"\", \"\\\"\\\"\")}\"'  # Escape double quotes\n",
    "    is_varchar = col_type.upper() in ['VARCHAR', 'STRING', 'TEXT', 'CHARACTER VARYING']\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    SELECT \n",
    "        '{col_name}' AS column_name,\n",
    "        '{col_type}' AS column_type,\n",
    "        COUNT(*) AS total_rows,\n",
    "        SUM(CASE WHEN {col_quoted} IS NULL THEN 1 ELSE 0 END) AS null_count,\n",
    "        COUNT(DISTINCT {col_quoted}) AS distinct_count\n",
    "    \"\"\"\n",
    "    \n",
    "    # Include empty string count for string columns\n",
    "    if is_varchar:\n",
    "        sql += f\"\"\",\n",
    "        SUM(CASE WHEN {col_quoted} = '' THEN 1 ELSE 0 END) AS empty_varchar_count\"\"\"\n",
    "    \n",
    "    # Add example value - using LIMIT instead of FILTER for PostgreSQL compatibility\n",
    "    if is_varchar:\n",
    "        sql += f\"\"\",\n",
    "        (SELECT {col_quoted} FROM {table_name} \n",
    "         WHERE {col_quoted} IS NOT NULL AND {col_quoted} != '' \n",
    "         LIMIT 1) AS example_value\"\"\"\n",
    "    else:\n",
    "        sql += f\"\"\",\n",
    "        (SELECT {col_quoted} FROM {table_name} \n",
    "         WHERE {col_quoted} IS NOT NULL \n",
    "         LIMIT 1) AS example_value\"\"\"\n",
    "    \n",
    "    # Add min/max for numeric or date-like types\n",
    "    if col_type.upper() in [\"INTEGER\", \"BIGINT\", \"SMALLINT\", \"NUMERIC\", \"DECIMAL\", \"REAL\", \"DOUBLE PRECISION\", \"TIMESTAMP\", \"DATE\", \"TIME\"]:\n",
    "        sql += f\"\"\",\n",
    "        MIN({col_quoted}) AS min_val,\n",
    "        MAX({col_quoted}) AS max_val\"\"\"\n",
    "    \n",
    "    sql += f\"\\nFROM {table_name}\"\n",
    "    return sql.strip()\n",
    "\n",
    "# Step 5: Generate and run queries\n",
    "queries = [\n",
    "    (row[\"column_name\"], row[\"column_type\"], generate_dqc_sql(row[\"column_name\"], row[\"column_type\"]))\n",
    "    for _, row in schema_df.iterrows()  # Fixed syntax error\n",
    "]\n",
    "\n",
    "def run_query_safe(col_name, col_type, sql):\n",
    "    \"\"\"Run DQC query safely with error handling\"\"\"\n",
    "    try:\n",
    "        # Execute query directly on PostgreSQL\n",
    "        result_df = pd.read_sql(sql, engine1)\n",
    "        return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error on column {col_name}: {e}\")\n",
    "        return pd.DataFrame([{\n",
    "            'column_name': col_name,\n",
    "            'column_type': col_type,\n",
    "            'total_rows': 0,\n",
    "            'null_count': 0,\n",
    "            'distinct_count': 0,\n",
    "            'error': str(e)\n",
    "        }])\n",
    "\n",
    "print(f\"\\nðŸš€ Running DQC on {len(queries)} columns...\")\n",
    "results = [run_query_safe(col, dtype, sql) for col, dtype, sql in queries]\n",
    "\n",
    "# Step 6: Combine all results\n",
    "dqc_results_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Step 7: Show the DQC summary\n",
    "print(\"\\nðŸ“Š === Data Quality Summary ===\")\n",
    "print(dqc_results_df)\n",
    "\n",
    "# Additional summary statistics\n",
    "if 'error' not in dqc_results_df.columns or dqc_results_df['error'].isna().all():\n",
    "    print(\"\\nðŸ“ˆ === Additional Insights ===\")\n",
    "    total_rows = dqc_results_df['total_rows'].iloc[0] if len(dqc_results_df) > 0 else 0\n",
    "    print(f\"Total rows in table: {total_rows:,}\")\n",
    "    \n",
    "    if total_rows > 0:\n",
    "        # Null percentage by column\n",
    "        dqc_results_df['null_percentage'] = (dqc_results_df['null_count'] / dqc_results_df['total_rows'] * 100).round(2)\n",
    "        \n",
    "        # Uniqueness ratio\n",
    "        dqc_results_df['uniqueness_ratio'] = (dqc_results_df['distinct_count'] / dqc_results_df['total_rows']).round(4)\n",
    "        \n",
    "        print(f\"\\nColumns with highest null percentages:\")\n",
    "        high_nulls = dqc_results_df.nlargest(5, 'null_percentage')[['column_name', 'null_percentage']]\n",
    "        for _, row in high_nulls.iterrows():\n",
    "            print(f\"  â€¢ {row['column_name']}: {row['null_percentage']}%\")\n",
    "        \n",
    "        print(f\"\\nColumns with low uniqueness (potential duplicates):\")\n",
    "        low_unique = dqc_results_df[dqc_results_df['uniqueness_ratio'] < 0.95].nsmallest(5, 'uniqueness_ratio')[['column_name', 'uniqueness_ratio']]\n",
    "        for _, row in low_unique.iterrows():\n",
    "            print(f\"  â€¢ {row['column_name']}: {row['uniqueness_ratio']} ratio\")\n",
    "\n",
    "# Clean up connections\n",
    "engine1.dispose()\n",
    "con.close()\n",
    "\n",
    "print(\"\\nâœ… Data Quality Check completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
